The database created by this project is valuable for the starup Sparkify as it contains data on many business dimensions - songs, artists, user log data. By using this they will be able to make relations on how the users are behaving, what do they like to listen and when. By using this database it will be easy to answer important business questions such as which artists and songs are most popular. These can help change for example the price poilicy of Sparkify.  

The database schema is following star schema design. In this case there are dimensional tables (songs, artists, time and users) and a fact table (songplays). The dimensinal tables can be connected to the fact table by primary-foreign key each table has. The input for the table creation is taken from two json data sources - log data and song data. The two are mapped by song id, artist id and song duration as both sources supposedly have this information in common. However, it is is worht mentioning that none of the songs are actually in common. That is the general songs database and the one on which songs are the users listening to have no overlaps. Time variables are hour of the day, month, year and weekday are extracted from the start date of the user in the log file. By using this type of star schema to organize the data, it is much easier for business users to understand and map the data they need in different aggregation queries.  

Example of these queries is for example which gender user are more common in the sample. Executing the query "select gender, count( * ) from users group by gender" returns that female are more than twice the number of the male users (4968 vs 2018). Another interesting analysis is which part of the week are the users most active. Executing the query "select weekday, count(* ) from time group by weekday" shows that only 1024 users have used Sparkify during the weekend and is far less than any workday. Last, but not least, it is important to know the allocation of users that paid for membership or use the app fpr free. The query "select level, count(* ) from users group by level" returns that 81% of the users use paid membership (5692 vs 1294).


ETL Process Flow:
1. Run the create_tables.py. This will create all the songs, artists, time, users and songplays tables empty and ready to populate.
2. Run etl.py which will read all the files in the data folder. This script will make and run all insert statements to populate the tables. In order to do this the process utilizes the script sql_queries.py which contains all drop, create and insert template statements. 
3. Run test.ipynb notebook to make sure the tables are create and filled in correctly. It displays top 5 rows of each of the tables songplays, users, songs, artists and time.

The last file in the repository etl.ipynb is not part of the database creation process but has been used as playground to understand and specify the logic needed to make up etl.py. For example, it uses only one song file to insert data in songs and artists tables. 
